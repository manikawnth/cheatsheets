{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def separate_train_test(csv_file, train_file, test_file, split_proportion=0.3):\n",
    "    with open(csv_file,mode='r') as infile, open(train_file,mode='w') as trainfile, open(test_file,mode='w') as testfile:\n",
    "        inrows = infile.readlines()\n",
    "        test_indexes = random.sample(range(len(inrows)), round(len(inrows)*split_proportion))\n",
    "        for ix,row in enumerate(inrows):\n",
    "            if ix in test_indexes:\n",
    "                testfile.write(row)\n",
    "            else:\n",
    "                trainfile.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory_path = 'C:\\\\Users\\\\maniksri\\\\Documents\\\\DataAnalysis\\\\'\n",
    "separate_train_test(directory_path + 'iris.csv', directory_path + 'iris_train.csv', directory_path + 'iris_test.csv', 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def separate_features_classes(csv_file, class_index):\n",
    "    import csv\n",
    "    features_array = []\n",
    "    classes_array = []\n",
    "    with open(csv_file,mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        for row in reader:\n",
    "            classes_array.append(row.pop(class_index))\n",
    "            features_array.append([float(item) for item in row])\n",
    "    return (features_array, classes_array)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.1, 3.5, 1.4, 0.2]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features,train_classes = separate_features_classes(directory_path + 'iris_train.csv', class_index=4)\n",
    "train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.6, 3.1, 1.5, 0.2]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features,test_classes = separate_features_classes(directory_path + 'iris_test.csv', class_index=4)\n",
    "test_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#group by class\n",
    "def group_by_class(features,classes):\n",
    "    grouped_classes = {}\n",
    "    for f,c in zip(features,classes):\n",
    "        if c not in grouped_classes.keys():\n",
    "            grouped_classes[c] = []\n",
    "        grouped_classes[c].append(f)\n",
    "        \n",
    "    return grouped_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#summarize by class\n",
    "N=0\n",
    "train_class_proportion = {}\n",
    "def summarize_by_class(features,classes):\n",
    "    import statistics\n",
    "    summarized_class = {} #mean, stdev\n",
    "    grouped_class = group_by_class(features,classes)\n",
    "    global N\n",
    "    N=0\n",
    "    global train_class_proportion\n",
    "    sample_count = {}\n",
    "    for label in grouped_class:\n",
    "        train_class_proportion[label] = len(grouped_class[label])\n",
    "        N = N + len(grouped_class[label])\n",
    "        features_array = zip(*grouped_class[label])\n",
    "        summarized_class[label] = []\n",
    "        for feature in features_array:\n",
    "            f_mean = statistics.mean(feature)\n",
    "            f_stdev = statistics.stdev(feature)\n",
    "            summarized_class[label].append((f_mean,f_stdev))\n",
    "    \n",
    "    for key,val in train_class_proportion.items():\n",
    "        train_class_proportion[key] = val / N\n",
    "    \n",
    "    return summarized_class\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setosa': 0.32, 'versicolor': 0.34, 'virginica': 0.34}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_by_class(train_features,train_classes)\n",
    "train_class_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calcuate Gaussian probability\n",
    "def calculate_gaussian_probability(x, stats):\n",
    "    import math\n",
    "    mean,stdev = stats\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_test_features_probabilities(test_features_array):\n",
    "    test_features_probabilities = []\n",
    "    trained_class_summary = summarize_by_class(train_features,train_classes)\n",
    "    \n",
    "    for item in test_features_array:\n",
    "        item_probability = {}\n",
    "        for trained_class,feature_summary in trained_class_summary.items():\n",
    "            item_parms = (zip(item, feature_summary))\n",
    "            prob = 1 * train_class_proportion[trained_class]\n",
    "            for item_parm in item_parms:\n",
    "                prob = prob * calculate_gaussian_probability(item_parm[0],item_parm[1])\n",
    "            item_probability[trained_class] = prob\n",
    "        test_features_probabilities.append(item_probability)\n",
    "    return test_features_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_probabilities = calculate_test_features_probabilities(test_features)\n",
    "test_class_pred = []\n",
    "\n",
    "for test_item in test_probabilities:\n",
    "    prob_class = None\n",
    "    max_prob = 0\n",
    "    for key,val in test_item.items():\n",
    "        if val > max_prob: \n",
    "            max_prob = val\n",
    "            prob_class = key\n",
    "    test_class_pred.append(prob_class) \n",
    "\n",
    "temp = zip(test_class_pred,test_classes) \n",
    "total_test_items = 0\n",
    "total_test_correct = 0\n",
    "\n",
    "for item in temp:\n",
    "    total_test_items += 1\n",
    "    if(item[0] == item[1]): total_test_correct += 1\n",
    "\n",
    "accuracy = total_test_correct / (total_test_items * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_features,train_classes)\n",
    "clf_pred = clf.predict(test_features)\n",
    "\n",
    "print(accuracy_score(clf_pred,test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
